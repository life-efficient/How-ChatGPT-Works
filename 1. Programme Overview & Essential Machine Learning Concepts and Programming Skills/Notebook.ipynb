{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essential ML concepts\n",
    "\n",
    "## What is machine learning?\n",
    "\n",
    "Almost any problem can be framed as mapping from some input to some output\n",
    "\n",
    "# TODO diagram of example input-outputs\n",
    "\n",
    "Some problems are easy to solve because we have managed to find the function that maps between them.\n",
    "\n",
    "# diagram of easy problems\n",
    "\n",
    "For other problems of interest, it is extremely hard to find out what that function is.\n",
    "\n",
    "# TODO diagram of hard problems\n",
    "\n",
    "> Machine learning is the task of having a computer find this function for itself.\n",
    "\n",
    "A more technical definition is that machine learning is: any computer system that can improve on a task (T) as measured by a performance metric (P) with experience (E)\n",
    "\n",
    "As we will see, the most important functions in machine learning are parametric - that is, they have parameters which change the input-output relationship of the function.\n",
    "\n",
    "The learning in machine learning, is the adjusting of these parameters so that the function changes\n",
    "\n",
    "# TODO gif of changing linear regression prediction and parameters\n",
    "\n",
    "\n",
    "## How does machine learning learn those functions?\n",
    "\n",
    "The most important algorithm that we will need to be aware of for this program is how a machine learning algorithm can learn by repeatedly updating its parameters by comparing it's predictions with the label given for lots of different input examples.\n",
    "\n",
    "Overall, it works like this:\n",
    "1. Get an example\n",
    "1. Make a prediction from the inputs by passing them through the function\n",
    "1. Compare the prediction with the target to compute the error\n",
    "1. Update the function parameters in such a way that reduces the error\n",
    "1. Repeat\n",
    "\n",
    "## The 4 typical components of any machine learning algorithm\n",
    "\n",
    "1. The data\n",
    "1. The model\n",
    "1. The criterion\n",
    "1. The optimiser\n",
    "\n",
    "### Component 1: Data\n",
    "\n",
    "> The data is a set of _examples_ that appear in your dataset\n",
    "\n",
    "Examples in a dataset usually consist of 2 things: \n",
    "1. _Features_\n",
    "    - The inputs\n",
    "    - The thing you are using to predict the output\n",
    "    - Also referred to as:\n",
    "        - Inputs\n",
    "1. _Labels_\n",
    "    - The output\n",
    "    - Also referred to as \n",
    "        - Outputs\n",
    "        - Targets\n",
    "\n",
    "Example datasets:\n",
    "- A large body of text, where the examples are different sentences\n",
    "- A set of examples containing images and their classification\n",
    "- A set of examples containing features of different houses and the price of that house\n",
    "\n",
    "In the most usual case, features of an example can be represented as a vector, and the labels as a scalar.\n",
    "\n",
    "## TODO vector, scalar features labels\n",
    "\n",
    "All of the data can be represented in a single matrix, where the rows are examples, and the columns are different features of each of those examples. We call this the design matrix.\n",
    "\n",
    "#### Show some example data e.g. house pricing\n",
    "\n",
    "> Your data defines your problem, and what the model learns\n",
    "\n",
    "Whether your targets are continuous or categorical values determines whether you have a _regression_ or _classification_ problem\n",
    "- Regression: Targets are continuous\n",
    "    - E.g. House price prediction\n",
    "- Classification: Targets are categorical\n",
    "    - E.g. Which word should come next following the input text?\n",
    "\n",
    "### Component 2: Model\n",
    "\n",
    "> The model takes an input, and uses it to predict an output.\n",
    "\n",
    "# TODO diagram x -> y model/f\n",
    "\n",
    "For example:\n",
    "- Your model might take in a set of text and predict the next word\n",
    "- Your model might take in the joint positions and accelerations of a robot and use it to predict the next move\n",
    "- Your model might take in the features of a house and use it to predict the price\n",
    "\n",
    "Because in most important cases, the model is a mathematical function, the data needs to be represented numerically. \n",
    "This can be a challenge for some common data types like text.\n",
    "\n",
    "### Component 3: The Criterion\n",
    "\n",
    "> The criterion is a function that measures how bad your model is\n",
    "\n",
    "A criterion may commonly also be referred to as:\n",
    "- The loss function\n",
    "- The error function\n",
    "\n",
    "The value returned from the criterion is a measure of how _bad_ your model is, which may also be known as:\n",
    "- The loss\n",
    "- The error\n",
    "\n",
    "#### Mean Squared Error\n",
    "\n",
    "The most important loss function for regression is the _mean squared error_.\n",
    "\n",
    "# TODO mean squared error diagram\n",
    "\n",
    "#### Cross Entropy Loss\n",
    "\n",
    "The most important loss function for classification is the _cross entropy loss_.\n",
    "\n",
    "For classification tasks, your model will output a probability for each possible class. \n",
    "The cross entropy loss function is designed to take in the probability predicted for _the true class label_, and return:\n",
    "- a low loss if that probability is high\n",
    "    - The best probability to predict for the true label would be 1, which will give you a loss of zero\n",
    "- a high loss if that probability is low.\n",
    "    - The worst probability to predict for the true label would be 0, which will give you an infinite loss\n",
    "\n",
    "As you optimise your model, you should see the loss decrease. Graphically, this produces what is known as a _loss curve_.\n",
    "\n",
    "# TODO ![](./images/tensorboard-loss-curve.png)\n",
    "\n",
    "# TODO cross entropy loss diagram\n",
    "\n",
    "### Component 4: The Optimiser\n",
    "\n",
    "> The optimiser is an algorithm used to update the model so that it improves\n",
    "\n",
    "#### Gradient descent\n",
    "\n",
    "The most important optimiser to be aware of is called _stochastic gradient descent_.\n",
    "\n",
    "You can picture it doing this:\n",
    "\n",
    "# TODO ![](./images/gradient-descent-visualisation.png)\n",
    "\n",
    "It works as follows:\n",
    "- Take a batch of examples and predict their targets\n",
    "- Compute the gradient of the objective (the thing you want to minimise - in our case, the loss) with respect to the model parameters \n",
    "    - This tells you \"for each parameter, if I were to increase it slightly, how quickly would the objective increase\n",
    "    - The gradient is a scalar value for each model parameter\n",
    "- Update the parameters in the direction that would reduce the loss\n",
    "    - This direction is the opposite sign of the gradient\n",
    "        - If the parameter gradient is positive, then that means that increasing it would increase the loss, so it should be decreased\n",
    "        - If the parameter gradient is negative, then that means that decreasing it would increase the loss, so it should be increased\n",
    "    - We shift each parameter by an amount proportional to the gradient, scaled by a value we call the learning rate, $\\alpha$\n",
    "        - The learning rate controls the step size of each update\n",
    "            - Too small and the model will take too long to converge\n",
    "            - Too large and the model will diverge\n",
    "\n",
    "Mathematically, this is repeated until the stopping condition is met:\n",
    "\n",
    "## $\\hat{y} = model(x, w)$\n",
    "## $ L = loss(\\hat{y}, y)$\n",
    "## $ w \\leftarrow w - \\alpha \\frac{\\partial{L}}{\\partial w}$ \n",
    "\n",
    "Gradient descent requires that:\n",
    "- The model and loss function are continuous differentiable functions\n",
    "- The model is parametric\n",
    "\n",
    "\n",
    "## Machine learning jargon\n",
    "\n",
    "\n",
    "### \n",
    "\n",
    "## Other essential machine learning concepts to understand\n",
    "\n",
    "### Supervised & Unsupervised data\n",
    "\n",
    "Supervised data is a set of data where each example contains both an input and an output.\n",
    "- House features -> House price label\n",
    "\n",
    "Unsupervised data, on the other hand, is a set of data where you only have features - no labels.\n",
    "- Corpus of unlabelled text\n",
    "\n",
    "### Thinking about high dimensional data\n",
    "\n",
    "# diagram of 1d, 2d, 3d data\n",
    "\n",
    "Because we live in a 3-D world, we can visualise arrows with 1 dimension, 2 dimensions, and 3 dimensions. Each of these, is equivalent to a vector containing the coordinates of the end of the arrow.\n",
    "\n",
    "For higher dimensional objects, like a vector with 4 or more elements, you can still think of it like an arrow, but you can't quite visualise what it looks like.\n",
    "\n",
    "> 'To visualise 13 dimensional space, simply think of 3 dimensional space, and say \"13\" loudly' - Geoff Hinton\n",
    "\n",
    "\n",
    "### hyperparameters\n",
    "\n",
    "Gradient descent optimises some parameters that control the function which the model represents directly, by directly changing their values during the training process where the model iteratively makes predictions and improves.\n",
    "\n",
    "> Hyperparameters are parameters that cannot be optimised directly, or that are difficult to optimise because they need to be set before training\n",
    "\n",
    "Hyperparameters include:\n",
    "- The type of function that represents the model e.g. neural network vs decision tree\n",
    "- The learning rate of the optimiser\n",
    "- The architecture of the neural network model\n",
    "\n",
    "\n",
    "### The training set, the validation set, and the test set\n",
    "\n",
    "When we train machine learning algorithms, we typically split the data into 3 sets, each with a different use.\n",
    "- The training set\n",
    "    - Used for updating model parameters that can be optimised directly\n",
    "- The validation set\n",
    "    - Used for evaluating trained models' generalisation capability\n",
    "    - Used to compare between different models and different model hyperparameters and make choices about which to use\n",
    "    - NOT used for evaluating final performance\n",
    "- The test set\n",
    "    - Used ONLY to determine a final measure of performance of the model on totally unseen data\n",
    "    - Never used to make any decision about which model or model parameters are better \n",
    "        - doing so would be cheating - picking the best model based on data its final performance will be evaluated on\n",
    "    - Different to the validation set. The validation set is used to make choices about the model \n",
    "\n",
    "### Overfitting & underfitting\n",
    "\n",
    "- Underfitting: When your model is not able to learn to perform well enough on the training set.\n",
    "- Overfitting: When your model learns to fit the training set too closely.\n",
    "\n",
    "# TODO ![](./images/overfitting-underfitting.png)\n",
    "\n",
    "Both overfitting and underfitting can lead to poor performance on unseen examples.\n",
    "\n",
    "Symptoms of overfitting and underfitting can appear in your loss curves.\n",
    "\n",
    "<!-- ### Important Performance Metrics -->\n",
    "\n",
    "### Regularisation\n",
    "\n",
    "> Regularisation is any method used to reduce the generalisation error of a model\n",
    "\n",
    "# TODO ![](./images/overfitting-underfitting.png)\n",
    "\n",
    "\n",
    "\n",
    "# Essential Python programming concepts\n",
    "\n",
    "## Variables\n",
    "\n",
    "## Lists\n",
    "\n",
    "## Dictionaries\n",
    "\n",
    "## Functions\n",
    "\n",
    "## Classes\n",
    "\n",
    "## Inheritance\n",
    "\n",
    "## Magic methods\n",
    "\n",
    "\n",
    "\n",
    "# Essential Mathematical Concepts\n",
    "\n",
    "\n",
    "## Tensors\n",
    "\n",
    "> In machine learning, a tensor is a generalisation of a matrix with more than 2 dimensions\n",
    "\n",
    "# TODO ![](./images/vector-matrix-tensor.png)\n",
    "\n",
    "### Vector & matrix notation\n",
    "\n",
    "We typically represent vectors with lower-case mathematical symbols, and matrices with upper-case mathematical symbols.\n",
    "\n",
    "A vector element might have a subscript to represent its position in the vector.\n",
    "\n",
    "A matrix element might have a double subscript to represent its position in the vector, where the first subscript represents the row position, and the second the column position.\n",
    "\n",
    "### Matrix multiplication\n",
    "\n",
    "### Broadcasting\n",
    "\n",
    "In many cases when programming, the dimensions of a calculation don't match mathematically, but the calculation still works - such as when multiplying a column vector by a matrix. \n",
    "This is because the program assumes that you want to _broadcast_ that vector across the matrix in a way that does make sense.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dot product\n",
    "\n",
    "### Cosine similarity\n",
    "\n",
    "### e & log\n",
    "\n",
    "### PI\n",
    "\n",
    "### SIGMA\n",
    "\n",
    "## Real numbers\n",
    "\n",
    "## Differentiation\n",
    "\n",
    "## probability distributions\n",
    "\n",
    "\n",
    "## Introducing the map of how we will build up to ChatGPT\n",
    "\n",
    "- We need to be able to understand complex data like text\n",
    "- We need to generate text data\n",
    "- We need to be able to make sure the system is safe to use\n",
    "\n",
    "## Where are we on the map of our journey to ChatGPT?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 (main, Nov 24 2022, 08:09:04) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3e643153f50b336c1c7a9d4d544c5113a86fd55c72312d55d3acd153a8b13ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
