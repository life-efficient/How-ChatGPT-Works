{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How ChatGPT Works Part 2: The Rewards Model\n",
    "\n",
    "> Given a prompt and a response, the reward model is a model trained to predict a scalar value representing how good a response is\n",
    "\n",
    "## Data Collection and Labelling\n",
    "\n",
    "The model is trained on a dataset of multiple responses to the same prompt.\n",
    "\n",
    "To construct a dataset, human labellers were asked to rank different responses to the same prompt.\n",
    "\n",
    "With too many options, decision paralysis can kick in (where it takes too long to decide between a lot of options).\n",
    "A common technique used to simplify this can be to provide only a limited set of options.\n",
    "\n",
    "## The Training Objective\n",
    "\n",
    "\n",
    "\n",
    "> The absolute value of the reward predicted by the model is not important. What's important, is the difference between the reward predicted for different responses to a prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class RewardDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, max_len=512):\n",
    "        \"\"\"Initializes the dataset.\"\"\"\n",
    "        self.data = pd.read_csv('data.csv')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns the example in the dataset at the given index.\"\"\"\n",
    "        context = self.data[idx]['context']\n",
    "        response = self.data[idx]['response']\n",
    "        return context, response\n",
    "        # text = self.tokenizer.encode(text, add_special_tokens=True, max_length=self.max_len, truncation=True)\n",
    "        # return torch.tensor(text)\n",
    "\n",
    "\n",
    "dataset = RewardDataset(tokenizer)\n",
    "print(\"Dataset length:\", len(dataset))\n",
    "example_idx = random.randint(0, len(dataset))])\n",
    "print(dataset[example_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ChatGPT2RewardModel:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, context, response):\n",
    "        \"\"\"\n",
    "        Returns a scalar value representing the reward for this response, given the context.\n",
    "        Args:\n",
    "            context (str): The context. aka. the prompt.\n",
    "            response (str): The response. aka. the response to the prompt.\n",
    "        Returns:\n",
    "            float: The reward for generating this response given the context.    \n",
    "        \"\"\"\n",
    "        context = self.tokenizer.encode(context, return_tensors='pt')\n",
    "        response = self.tokenizer.encode(response, return_tensors='pt')\n",
    "        input_ids = torch.cat([context, response], dim=-1)\n",
    "\n",
    "        return \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
